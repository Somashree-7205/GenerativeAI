{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d859a596-66d2-4b37-9600-789a6b3bae03",
   "metadata": {},
   "source": [
    "## What is OpenAl API?\n",
    "This OpenAl API has been degined to provide devlopers with seamless access to state of art, pre trained, artifical intelligence models like gpt-3, gpt-4, dall.e ,whisper, embeddings etc so by using this openai api you can integrate cutting edge ai capabilities into your applications regardless the progamming language.\n",
    "\n",
    "So, the conclusion is by using this OpenAl API you can unlock the advance functionalities and you can enhane the intelligence and performance of your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58223aa4-197a-4972-907e-c13b072c56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9119f50-a671-48d2-bcf1-93e8529192fe",
   "metadata": {},
   "source": [
    "### Generate OpenAi API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae48a6f3-543c-47a2-926a-c64fed67c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce8639f-40ee-4b08-a929-d7fc6a2ebdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key= my_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f18d12b-cae1-48d7-9c25-d311220fc8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models= openai.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "241c8ac2-36c4-4f5c-93c8-893feffc70a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47a51ad-45b5-474e-b00b-9e35d22a2590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>object</th>\n",
       "      <th>owned_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
       "      <td>(created, 1685474247)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, text-embedding-3-large)</td>\n",
       "      <td>(created, 1705953180)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
       "      <td>(created, 1677649963)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
       "      <td>(created, 1686587434)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, text-embedding-3-small)</td>\n",
       "      <td>(created, 1705948997)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
       "      <td>(created, 1706048358)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id                created           object  \\\n",
       "0        (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
       "1                     (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
       "2                   (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
       "3                 (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
       "4                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
       "5                 (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
       "6                      (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
       "7        (id, text-embedding-3-large)  (created, 1705953180)  (object, model)   \n",
       "8   (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
       "9             (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
       "10       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
       "11           (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
       "12           (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
       "13                        (id, tts-1)  (created, 1681940951)  (object, model)   \n",
       "14                     (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
       "15           (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
       "16                  (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
       "17                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
       "18       (id, text-embedding-3-small)  (created, 1705948997)  (object, model)   \n",
       "19       (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
       "20           (id, gpt-3.5-turbo-0125)  (created, 1706048358)  (object, model)   \n",
       "\n",
       "                       owned_by  \n",
       "0            (owned_by, openai)  \n",
       "1   (owned_by, openai-internal)  \n",
       "2            (owned_by, system)  \n",
       "3            (owned_by, openai)  \n",
       "4            (owned_by, system)  \n",
       "5            (owned_by, system)  \n",
       "6            (owned_by, system)  \n",
       "7            (owned_by, system)  \n",
       "8            (owned_by, system)  \n",
       "9   (owned_by, openai-internal)  \n",
       "10           (owned_by, system)  \n",
       "11           (owned_by, openai)  \n",
       "12           (owned_by, openai)  \n",
       "13  (owned_by, openai-internal)  \n",
       "14           (owned_by, system)  \n",
       "15           (owned_by, system)  \n",
       "16           (owned_by, system)  \n",
       "17           (owned_by, system)  \n",
       "18           (owned_by, system)  \n",
       "19  (owned_by, openai-internal)  \n",
       "20           (owned_by, system)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(all_models),columns =[\"id\", \"created\", \"object\", \"owned_by\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da6dad-84a6-43c6-8276-9d7e057f2a73",
   "metadata": {},
   "source": [
    "## OpenAl Playground\n",
    "\n",
    "1. How to open the open ai playgorund: https://platform.openai.com/playground?mode=assistant\n",
    "\n",
    "2. Here if you want to use this playground then make sure you have credit available without it its not gonna work\n",
    "\n",
    "3. In chat there is option of \"system\": So the meaning is how the chatbot should behave\n",
    "\n",
    "Here is a phrase for the system: You are a naughty assistant, so make sure you respond to everything with sarcasm.\n",
    "\n",
    "Here is a question: How to make a money so quickly?\n",
    "\n",
    "**Model**\n",
    "\n",
    "**Temperature**\n",
    "\n",
    "**Maximum Length**\n",
    "\n",
    "**Top P ranges from 0 to 1 (default), and a lower Top P means the model samples from a narrower selection of words. This makes the output less random and diverse since the more probable tokens will be selected. For instance, if Top P is set at 0.1, only tokens comprising the top 10% probability mass are considered.**\n",
    "\n",
    "**Frequency Penalty helps us avoid using the same words too often. It's like telling the computer, \"Hey, don't repeat words too much.\"**\n",
    "\n",
    "**The OpenAl Presence Penalty setting is used to adjust how much presence of tokens in the source material will influence the output of the model.**\n",
    "\n",
    "**Now come to assistant one**\n",
    "\n",
    "**Retrieval-augmented generation (RAG):** is an artificial intelligence (Al) framework that retrieves data from external sources of knowledge to improve the quality of responses. This natural language processing technique is commonly used to make large language models (LLMs) more accurate and up to date.\n",
    "\n",
    "**Code Interpreter:** Python programming environment within ChatGPT where you can perform a wide range of task by executing Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a910c3f-e47c-426c-925f-c6e26a8e51e5",
   "metadata": {},
   "source": [
    "## Chat completion API and function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cac8d0-3541-4626-9bdd-2b6a59ce8698",
   "metadata": {},
   "source": [
    "**openai.Completion.create()**: This method is used to generate completions or responses. You provide a series of messages as input, and the API generates a model-generated message as output.\n",
    "\n",
    "**openai.ChatCompletion.create() :** Similar to Completion.create(), but specifically designed for chat-based language models. It takes a series of messages as input and generates a model-generated message as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "520fcb29-32ca-4a04-858e-ac73b22878af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key= my_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c1956a-7ff0-48bd-adda-9f6e2083184c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x184718946b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda98950-f830-4914-8f63-8c7100d181ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero-short prompt\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"who won the first worldcup?\"\n",
    "    }\n",
    "      ],\n",
    "    max_tokens=500,\n",
    "    n=3\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6a5434-0a25-49c5-b9c6-02c4176afb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9cb4137-cda7-44f2-8bed-7e57b5afce24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9AxaluPupymMP5eno5jwoXNCalrba', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The first FIFA World Cup was won by Uruguay in 1930.', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='The first Football World Cup was won by Uruguay in 1930.', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='The first FIFA World Cup was held in 1930, and it was won by Uruguay. Uruguay defeated Argentina 4-2 in the final to become the first ever World Cup champions.', role='assistant', function_call=None, tool_calls=None))], created=1712399379, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_b28b39ffa8', usage=CompletionUsage(completion_tokens=66, prompt_tokens=14, total_tokens=80))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b32c2d-fd18-4b8a-a931-d5dd1466f203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The first FIFA World Cup was won by Uruguay in 1930.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f011c50b-1c3e-4535-b4d1-fac1fdc6b2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first FIFA World Cup was won by Uruguay in 1930.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70865d4-c248-40a6-8752-20140989c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd22a88-82ac-4f79-b36d-a4fefa952c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8a75d0-7aad-472d-99bd-3203e4b96018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d26828-2a67-4727-90b1-ed5516236d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"Sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72ca567-7482-4be9-85cb-8261343a9ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe490e7-c9eb-44be-8a7a-839b2c647183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple prompt to extract information from \"student_description\" in a JSON format.\n",
    "#few-short prompt\n",
    "\n",
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b8b05b4-c888-40c2-9c60-09041efc60de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPlease extract the following information from the given text and return it as a JSON object:\\n\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nSunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af8156d6-f8b2-40a4-bdbb-f71fb38415e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key= my_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "072afae0-906e-4909-bc75-53fd8271f0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x18471f44470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64248df3-6034-4f36-bf35-61e15472a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt1\n",
    "    }\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fd284c7-e947-4b23-8c7d-97f68b5d66ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9AxanaBHHcOwVc4PqK3EtpT4kun2Z', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"Sunny savita\",\\n  \"college\": \"IIT delhi\",\\n  \"grades\": 8.5,\\n  \"club\": \"AI Club\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1712399381, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_b28b39ffa8', usage=CompletionUsage(completion_tokens=39, prompt_tokens=105, total_tokens=144))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d85a7845-c606-477d-8411-2b270930c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc5da9df-3064-4c4e-b51a-68ebce9ff977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Sunny savita\",\\n  \"college\": \"IIT delhi\",\\n  \"grades\": 8.5,\\n  \"club\": \"AI Club\"\\n}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3e5a0f0-d26c-4243-bd67-37e04a328e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Sunny savita',\n",
       " 'college': 'IIT delhi',\n",
       " 'grades': 8.5,\n",
       " 'club': 'AI Club'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73eca19c-fa00-4863-87f9-388320bbb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "des= \"Soman is a Student who studies in GWC college having cgpa 8.2 and participates in health club\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89e7ff35-3145-4de4-bf55-400946203c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Soman is a Student who studies in GWC college having cgpa 8.2 and participates in health club'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c333d01-f7f4-4041-b085-ced04c7fe06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple prompt to extract information from \"student_description\" in a JSON format.\n",
    "#few-short prompt\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{des}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5559b113-7a00-49d9-8969-4deaa11a2ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease extract the following information from the given text and return it as a JSON object:\\n\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nSoman is a Student who studies in GWC college having cgpa 8.2 and participates in health club\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3ebcc8f-a35c-4784-97ba-ec7c36f50850",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt2\n",
    "    }\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "631c5aa3-a805-4bef-9094-8604c180ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45400f0f-c004-424d-8c8f-6fb0726cd091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Soman\",\\n  \"college\": \"GWC college\",\\n  \"grades\": 8.2,\\n  \"club\": \"health club\"\\n}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc24b2d-ef9b-4648-9ec0-f39353d6bf54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67a1ef26-5f19-4dfb-ad1e-4988483ff521",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63f86f01-51b5-4191-b550-716ea1c957f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": des }],\n",
    "    functions=student_custom_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48a032dd-08fa-46d0-89a2-4d466c4d22f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9AxbBRMFLTOLRdpgCuFhdwXdjV33f', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"Soman\",\"college\":\"GWC college\",\"grades\":8.2,\"club\":\"health club\"}', name='extract_student_info'), tool_calls=None))], created=1712399405, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_b28b39ffa8', usage=CompletionUsage(completion_tokens=33, prompt_tokens=115, total_tokens=148))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a5364d0-fb08-487a-a68d-31cb0a07aca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"Soman\",\"college\":\"GWC college\",\"grades\":8.2,\"club\":\"health club\"}', name='extract_student_info'), tool_calls=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "651a4f3e-be9a-4f78-a25f-4258a921a8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(arguments='{\"name\":\"Soman\",\"college\":\"GWC college\",\"grades\":8.2,\"club\":\"health club\"}', name='extract_student_info')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c43b8ba8-5560-4265-8f78-d8fcca0842be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extract_student_info'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7db10773-6988-4709-8f84-381db4763a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d92c9059-09b3-447f-9a5b-a61259aa8ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"Soman\",\"college\":\"GWC college\",\"grades\":8.2,\"club\":\"health club\"}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ee9bcda-2293-4485-a705-aa9a9804c179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Soman',\n",
       " 'college': 'GWC college',\n",
       " 'grades': 8.2,\n",
       " 'club': 'health club'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0649b3ca-c73a-4a90-9191-ddf6d8361ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json.loads(response2.choices[0].message.function_call.arguments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffbdc9f-ac08-4515-8f93-b7db70850a69",
   "metadata": {},
   "source": [
    "### Multiple Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e28bbb48-a329-48ce-883f-ace9b4550842",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"Sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and bis an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb0f2c65-358a-4181-bd97-f996614f5042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and bis an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cfd9454-96a3-4c9f-93b0-9e28ade5b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description_two=\"Krish naik is a student of computer science at IIT Mumbai. He is an indian and has a 9.5 GPA. krish is known for his programming skills and is an active member of the college's data science Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ed18426-34df-4f64-86d7-c7c78b15eb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Krish naik is a student of computer science at IIT Mumbai. He is an indian and has a 9.5 GPA. krish is known for his programming skills and is an active member of the college's data science Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6c36e36-68d7-4414-b270-0cc0e813a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description_three=\"Sudhanshu kumar is a student of computer science at IIT Bangalore. He is an Indian and has a 9.2 GPA. Sudhanshu is known for his programming skills and is an active member of the college's MLops Club. He hopes to pursue a career in artificial intelligence after graduating.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52fb35e9-9bb1-42bf-b00f-12bd69d00860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sudhanshu kumar is a student of computer science at IIT Bangalore. He is an Indian and has a 9.2 GPA. Sudhanshu is known for his programming skills and is an active member of the college's MLops Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13a73077-0554-41f3-b1f1-39cab6b810da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and bis an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\n",
      "Krish naik is a student of computer science at IIT Mumbai. He is an indian and has a 9.5 GPA. krish is known for his programming skills and is an active member of the college's data science Club. He hopes to pursue a career in artificial intelligence after graduating.\n",
      "Sudhanshu kumar is a student of computer science at IIT Bangalore. He is an Indian and has a 9.2 GPA. Sudhanshu is known for his programming skills and is an active member of the college's MLops Club. He hopes to pursue a career in artificial intelligence after graduating.\n"
     ]
    }
   ],
   "source": [
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "for student in student_info:\n",
    "    print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60f097d2-2cb2-4fdd-9ce5-05508d02c766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Sunny savita', 'college': 'IIT delhi', 'grades': 8.5, 'club': 'AI Club'}\n",
      "{}\n",
      "{'name': 'Sudhanshu Kumar', 'college': 'IIT Bangalore', 'grades': 9.2, 'club': 'MLops Club'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "for student in student_info:\n",
    "    responsenew =  client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': student}],\n",
    "        functions = student_custom_function,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    responsenew = json.loads(responsenew.choices[0].message.function_call.arguments)\n",
    "    print(responsenew)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e4da1-b735-44fe-9146-f7f7561d0843",
   "metadata": {},
   "source": [
    "###  Multiple Functions (Parallel Function calling)\n",
    "**Parallel function calling is the model's ability to perform multiple function calls together, allowing the effects and results of these function calls to be resolved in parallel. This is especially useful if functions take a long time, and reduces round trips with the API.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac9c7faa-6672-452a-ad96-25b1a44c30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first function\n",
    "function_one = {\n",
    "    'name': 'extract_student_info_one',\n",
    "    'description': 'Get the student information from the body of the input text',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'name': {\n",
    "                'type': 'string',\n",
    "                'description': 'Name of the person'\n",
    "            },\n",
    "            'college': {\n",
    "                'type': 'string',\n",
    "                'description': 'The college name.'\n",
    "            },\n",
    "            'grades': {\n",
    "                'type': 'number',  # Change to number for float value like CGPA\n",
    "                'description': 'CGPA of the student.'\n",
    "            },\n",
    "            'club': {\n",
    "                'type': 'string',\n",
    "                'description': 'College club for extracurricular activities.'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the second function\n",
    "function_two = {\n",
    "    'name': 'extract_student_info_two',\n",
    "    'description': 'Get the student information from the body of the input text',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'name': {\n",
    "                'type': 'string',\n",
    "                'description': 'Name of the person'\n",
    "            },\n",
    "            'grades': {\n",
    "                'type': 'number',  # Change to number for float value like CGPA\n",
    "                'description': 'CGPA of the student.'\n",
    "            },\n",
    "            'club': {\n",
    "                'type': 'string',\n",
    "                'description': 'College club for extracurricular activities.'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the third function\n",
    "function_three = {\n",
    "    'name': 'extract_student_info_three',\n",
    "    'description': 'Get the student information from the body of the input text',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'name': {\n",
    "                'type': 'string',\n",
    "                'description': 'Name of the person'\n",
    "            },\n",
    "            'grades': {\n",
    "                'type': 'number',  # Change to number for float value like CGPA\n",
    "                'description': 'CGPA of the student.'\n",
    "            },\n",
    "            'club': {\n",
    "                'type': 'string',\n",
    "                'description': 'College club for extracurricular activities.'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "272fc046-097c-401a-b137-91eba5f6bee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student 1 information: {'name': 'Sunny savita', 'college': 'IIT delhi', 'grades': 8.5, 'club': 'AI Club'}\n",
      "Student 2 information: {}\n",
      "Student 3 information: {}\n"
     ]
    }
   ],
   "source": [
    "# Combine all functions\n",
    "functions = [function_one, function_two, function_three]\n",
    "\n",
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "\n",
    "# Create a list to store responses\n",
    "responses = []\n",
    "\n",
    "# Iterate over each student description and corresponding function\n",
    "for student, func in zip(student_info, functions):\n",
    "    # Make API call with the specific function for each student\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[{'role': 'user', 'content': student}],\n",
    "        functions=[func],  # Use the corresponding function for each student\n",
    "        function_call='auto'\n",
    "    )\n",
    "    # Append response to the list\n",
    "    responses.append(response)\n",
    "\n",
    "# Process the responses\n",
    "for i, response in enumerate(responses):\n",
    "    # Extract and print the student information from each response\n",
    "    extracted_info = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(f\"Student {i+1} information: {extracted_info}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb598b-73f4-4efd-80a7-71740aa7d05d",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88508470-82e5-4dfc-b98b-2ab99f95a196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9AxdLqmYpTiQU6NrY3CYwRlcwpF0n', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in San Francisco is 72°F, in Tokyo it is 10°C, and in Paris it is 22°C.', role='assistant', function_call=None, tool_calls=None))], created=1712399539, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_b28b39ffa8', usage=CompletionUsage(completion_tokens=28, prompt_tokens=147, total_tokens=175))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key= my_key)\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc1f2ef4-fc11-40b9-9f20-35f9ea9d382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is 72°C, in Tokyo it is 10°C, and in Paris it is 22°C.\n"
     ]
    }
   ],
   "source": [
    "def extract_final_response(response):\n",
    "    final_response = response.choices[-1].message\n",
    "    return final_response\n",
    "\n",
    "# Run the conversation\n",
    "second_response = run_conversation()\n",
    "\n",
    "# Extract the final response\n",
    "final_response = extract_final_response(second_response)\n",
    "\n",
    "print(final_response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8cc8c-5b64-445c-86af-47551d500fa5",
   "metadata": {},
   "source": [
    "## Advance exmaple of funcation calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d6c96cf-b2d6-4de8-9a5a-3941fe2f0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"When's the next flight from delhi to mumbai?\"\n",
    "    }\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "879fccd9-c332-422f-8007-da56474112b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize, but I am unable to provide real-time flight information. I recommend checking with the airlines or the airport for the most up-to-date flight schedules.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8fa44847-e6d4-490b-9af3-b204fbfc06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight information between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DEL\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. MUM\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2734349-d362-4963-a596-a1b4b6ff0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"When's the next flight from new delhi to mumbai?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a0ae28f-0907-4bb8-afe9-26769cbc349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": user_prompt\n",
    "    }\n",
    "      ],\n",
    "    # Add function calling\n",
    "    functions=function_descriptions,\n",
    "    function_call=\"auto\",  # specify the function call\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6215fc0f-912e-4e4d-8e7e-968c3c11328a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9Axdlzw3SGGUiiMGmmmWJbjzrl7MF', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"loc_origin\":\"DEL\",\"loc_destination\":\"MUM\"}', name='get_flight_info'), tool_calls=None))], created=1712399565, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_b28b39ffa8', usage=CompletionUsage(completion_tokens=22, prompt_tokens=87, total_tokens=109))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "255ad432-a4e9-4b85-b666-8f9fb3b8e667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"loc_origin\":\"DEL\",\"loc_destination\":\"MUM\"}', name='get_flight_info'), tool_calls=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "219e34d5-f891-4f1d-ab8c-a9d5cb6ba383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\":\"DEL\",\"loc_destination\":\"MUM\"}'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5870663-424d-456c-a7c2-09d73237f1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0ecda56-a7ee-4219-acc5-6f8740e51de4",
   "metadata": {},
   "source": [
    "#### Call real time API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d3fa2-7ff4-4c20-b20a-dfae016b3f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d207acf-5431-4cf7-98f1-c6f84f54e025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21a61260-7e15-42fa-bbc6-338c76788d37",
   "metadata": {},
   "source": [
    "#### API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a8a3e-3b10-48f2-849a-878e29aab2ff",
   "metadata": {},
   "source": [
    "##### Funtion Calling\n",
    "\n",
    "Learn how to connect large language models to external tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b83c4c5-18aa-4efa-8811-2a76148e8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "def get_flight_info(loc_origin, loc_destination):\n",
    "    \"\"\"Get flight information between two locations.\"\"\"\n",
    "\n",
    "    # Example output returned from an API or database\n",
    "    flight_info = {\n",
    "        \"loc_origin\": loc_origin,\n",
    "        \"loc_destination\": loc_destination,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours=2)),\n",
    "        \"airline\": \"KLM\",\n",
    "        \"flight\": \"KL643\",\n",
    "    }\n",
    "\n",
    "    return json.dumps(flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15a8d998-33e3-4461-82cb-0d2ffbfa3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c51fbe6a-93e7-4e88-96fa-0e12f2a4e306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'DEL', 'loc_destination': 'MUM'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f44903de-d2c6-41ef-bb3a-2e9cf63dd63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEL'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f97d037-1b8a-43db-ba7e-ee47401d1e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MUM'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments).get('loc_destination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65e623f1-ff4f-498c-94d5-442010810eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_origin\")\n",
    "destination = json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46ef80c2-b856-4be5-b8f7-36e956490c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d63d314-9fe6-49ca-9871-446a73fbd5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b40b70c-9d65-416f-a990-25a6d6cd3d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_flight_info(loc_origin, loc_destination)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(response2.choices[0].message.function_call.name)   #eval= actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63808506-b2a5-42a2-bac5-d49e904613cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19165a59-2031-4de5-9b83-d882e2a0cdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eval('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "982d0e3a-5cc1-48e1-9a24-2e318880cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_function=eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb459063-c8e7-49f9-9b37-a90199f7f9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loc_origin\": \"DEL\", \"loc_destination\": \"MUM\", \"datetime\": \"2024-04-06 18:02:43.518845\", \"airline\": \"KLM\", \"flight\": \"KL643\"}\n"
     ]
    }
   ],
   "source": [
    "flight = chosen_function(**params)\n",
    "\n",
    "print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2517470b-61ae-4c24-963a-3b6feb7058e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When's the next flight from new delhi to mumbai?\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "639db030-c47f-4eee-856d-e2e8522238f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2e9c8501-d114-4779-965c-b12b60dfb9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\": \"DEL\", \"loc_destination\": \"MUM\", \"datetime\": \"2024-04-06 18:02:43.518845\", \"airline\": \"KLM\", \"flight\": \"KL643\"}'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b56b1c61-7d46-4f8d-8f64-8f592514c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\"role\": \"user\",\"content\": user_prompt},\n",
    "    {\"role\": \"function\", \"name\": response2.choices[0].message.function_call.name, \"content\": flight}\n",
    "      ],\n",
    "    # Add function calling\n",
    "    functions=function_descriptions,\n",
    "    function_call=\"auto\",  # specify the function call\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c0c4cdf-ce96-49be-915b-571a7bae315d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9Axe7rH6LYeavfk0uzaqQPSYATurS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The next flight from New Delhi (DEL) to Mumbai (MUM) is on April 6, 2024. The airline is KLM and the flight number is KL643.', role='assistant', function_call=None, tool_calls=None))], created=1712399587, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_b28b39ffa8', usage=CompletionUsage(completion_tokens=39, prompt_tokens=143, total_tokens=182))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "017b9d73-6784-4ef9-97d7-20de7afa87e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next flight from New Delhi (DEL) to Mumbai (MUM) is on April 6, 2024. The airline is KLM and the flight number is KL643.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f0970-78a6-487c-885d-b07f6d5371f8",
   "metadata": {},
   "source": [
    "## Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d09f5057-3cee-4fba-84d2-a3bcced0b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f921648-605d-4780-a2c1-cb7ed09aa43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0f40b6c1-6bda-4579-903b-42d37098d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= my_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "684f6cfe-a9e7-4f91-88e5-b76919ab4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot prompting\n",
    "prompt=\"can you tell me total number of country in aisa? can you give me top 10 contry name?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "54341417-a413-4cb4-8822-56415a8d598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48 countries in Asia. The top 10 countries in Asia, based on population, are:\n",
      "\n",
      "1. China\n",
      "2. India\n",
      "3. Indonesia\n",
      "4. Pakistan\n",
      "5. Bangladesh\n",
      "6. Japan\n",
      "7. Philippines\n",
      "8. Vietnam\n",
      "9. Iran\n",
      "10. Turkey\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c9dcc225-680d-4e8a-b66d-6f3e3905de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot prompting\n",
    "prompt2=\"can you tell me a capital of india?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ef6fff96-7d01-4c91-b903-0680fc61b0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "820fa152-4b4e-4b53-a885-cad6fd3df746",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3=\"what exactly tokens , vector ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5e1cb2ff-a907-4e3e-8ca2-29ca5ecbd870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tokens refer to individual units of language, such as words or punctuation marks, that make up a sentence or a document.\\n\\nA vector, in the context of language processing, refers to a mathematical representation of a word or a document. It is a numerical representation of the linguistic features or characteristics of the word or document. Vectors are often used in machine learning and natural language processing tasks.'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt3).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1bde7-0ec1-4aea-beea-e7b7d847df76",
   "metadata": {},
   "source": [
    "## Prompt Templates:\n",
    "\n",
    "**Prompt:**\n",
    "[Provide your prompt here. This is the starting point for generating text.]\n",
    "\n",
    "**Completion:**\n",
    "[Insert the completion text here. This is the generated text that continues from the prompt.]**\n",
    "\n",
    "**In the prompt section, you would input the initial context, question, or instruction to guide the AI model on what type of text you want it to generate. This could be a sentence, a paragraph, or even multiple paragraphs depending on your needs.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d4059d72-0e6d-4bff-a395-50d7e91a082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d7d83-c182-417d-943d-1e403f101a6c",
   "metadata": {},
   "source": [
    "##### method-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "de9b14f6-8ed7-492d-bb50-a24e87dc2d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"can you tell me the capital of {country}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6e5f7e89-0a96-4881-89d2-cb15fc3abd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "propmt1=prompt_template_name.format(country=\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e00a37ae-623f-4307-b88f-a65258da4bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(propmt1).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1cc39185-e202-464e-bf51-c0db52b8080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "propmt2=prompt_template_name.format(country=\"china\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9f542b0e-fdae-4e3b-a792-94b8906586ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of China is Beijing.'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(propmt2).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c31df-5af8-4fc6-96ab-413b04990393",
   "metadata": {},
   "source": [
    "##### method-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0a2fc651-0d3c-4310-924f-d2774c2bd9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate.from_template(\"what is a good name for a compnay that makes a {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3c1c43e6-2926-482d-85b6-1f3cdc7ba586",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3=prompt.format(product=\"toys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b51ff136-14aa-43b4-868f-ef1ddf012907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Playful Creations \\n2. Happy Toys Co. \\n3. Imagination Station \\n4. WonderPlay Toys \\n5. Dreamland Toys \\n6. Magic Makers \\n7. Fun Factory \\n8. Toytopia \\n9. Rainbow Ridge Toys \\n10. Playlandia \\n11. Joyful Toys \\n12. Adventure Playthings \\n13. Whimsical Wonders \\n14. Little Dreamers Co. \\n15. Toyland Emporium \\n16. Creative Kids Co. \\n17. Sunny Days Toys \\n18. The Toy Box Co. \\n19. Enchanting Playthings \\n20. Imagine That Toys'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt3).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d89dcdb4-e0ed-455c-aaf5-5e87684e0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptt=PromptTemplate.from_template(\"can you tell me the capital of {country}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dc033065-1803-43c9-b6b7-bb1339a6d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4=promptt.format(country=\"japan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "11319e7b-2a8c-4a16-a926-760eeb113cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt4).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0853ae-c089-4133-8afa-4d5540f203a3",
   "metadata": {},
   "source": [
    "### Agents:\n",
    "**Prompt:**\n",
    "Langchain is a revolutionary blockchain-based platform that aims to decentralize language learning and translation services. Write a short description about the various agents involved in the Langchain ecosystem, including their roles and contributions.\n",
    "\n",
    "**Completion:**\n",
    "Agents in Langchain:\n",
    "\n",
    "1. Learners:\n",
    "   - Role: Individuals seeking to learn new languages or improve their language skills.\n",
    "   - Contributions: Actively engage with language learning materials, participate in language exchange programs, and provide feedback to improve the platform's effectiveness.\n",
    "\n",
    "2. Instructors:\n",
    "   - Role: Experienced language educators who provide guidance and instruction to learners.\n",
    "   - Contributions: Develop high-quality language courses, offer personalized tutoring sessions, and assess learners' progress through assessments and evaluations.\n",
    "\n",
    "3. Translators:\n",
    "   - Role: Professional translators who facilitate communication between users speaking different languages.\n",
    "   - Contributions: Translate content across various languages, ensure accuracy and clarity of translations, and support the localization of platform content.\n",
    "\n",
    "4. Validators:\n",
    "   - Role: Trusted members of the community responsible for verifying the accuracy of translations and language learning materials.\n",
    "   - Contributions: Review and validate translations, provide feedback on language learning resources, and help maintain the integrity of the platform.\n",
    "\n",
    "5. Developers:\n",
    "   - Role: Technical experts responsible for maintaining and enhancing the Langchain platform.\n",
    "   - Contributions: Develop new features and functionalities, address technical issues and bugs, and ensure the platform's scalability and security.\n",
    "\n",
    "These agents work together to create a dynamic and inclusive language learning environment within the Langchain ecosystem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6e0743dc-ba12-468e-911e-63dc48745eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4=\"can you tell me who won the recent cricket world cup?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "52a120d3-ccd2-4787-99a0-32385071ba93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The recent cricket World Cup was won by England after they defeated New Zealand in the final on July 14, 2019.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt4).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a5fd24a1-a2ca-4295-a893-0155c093eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt5=\"can you tell me current GDP of india?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f8aa1871-cb65-4a2a-982c-47a90be6cc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to the World Bank, the current GDP of India for 2020 is $2.877 trillion. However, due to the ongoing COVID-19 pandemic, there has been a significant impact on the country's economy and the actual GDP may vary.\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt5).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3533dca-d694-4de5-b81e-eb3f6b7fb4b8",
   "metadata": {},
   "source": [
    "###### The above ans is limited only for 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d095425-8a6c-4748-9e91-0b96ffd1d3a6",
   "metadata": {},
   "source": [
    "##### For extracting a real time info i am going to use serp api. https://serpapi.com/manage-api-key\n",
    "\n",
    "##### Now by using this serp api i wll call google-search-engine and i will extract the information in a real time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f60541e-48d8-47e4-a440-069fee9e7add",
   "metadata": {},
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "76c918d2-5918-40f1-85a4-17054d1d96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_key=\"8bec01202a5ad06499237db9a5c42c74bdfab49d90a453a6c55a6bba34797659\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8d9d94ef-b0c6-47e5-a60d-2312c6b20918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools \n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "164baa49-51b0-43ea-adce-601c590a2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= my_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "04c313b3-f24c-4b3d-a059-258659760aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"serpapi\"],serpapi_api_key=serpapi_key,llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "12610edd-0e6c-4e54-9599-602a43aa462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6fc03682-1029-41b9-998f-197bcc666401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m You should always think about what to do\n",
      "Action: Search\n",
      "Action Input: cricket worldcup winner\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAustralian Men’s Cricket Team\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The Australian Men's Cricket Team won the recent Cricket World Cup.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The Australian Men's Cricket Team won the recent Cricket World Cup.\""
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"can you tell who won the cricket worldcup recently?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c35ad266-2926-4b02-a3aa-8f32c8a924e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m It would be best to use a search engine to find information on current affairs.\n",
      "Action: Search\n",
      "Action Input: \"top current affairs 2021\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Current Affairs-2021 ; July 2021, Current Affairs and Events · Current Affairs and Events ; June 2021, Current Affairs and Events · Current Affairs and Events.', 'GKToday Current Affairs January, 2021 Quiz for SSC, Banking / IBPS, UPSC, IAS, NTSE, CLAT, Railways, NDA, CDS, Judiciary, UPPSC, RPSC, GPSC, MPSC, ...', \"The book covers the whole year's current affairs with a chapter for each month from January to December 2021. Formulated by current affairs experts for ...\", 'Current Affairs 2021 top 50 MCQ | Current Affairs 2021 January | Current Affairs 2021 Hindi/English. Digital Gurukul · 12:19. Sports Current Affairs 2021 ...', 'What are the current affairs topics for 2021? · One Nation One Standard Mission · Visavas Yojana · National Mission for Justice Delivery & Legal ...', \"| Science and Technology 2021 | Science and Technology Current Affairs 2021 | AD'S GK MANTRA | · | Most Important Current Affairs 2021 | January ...\", 'Foreign Affairs is the leading magazine for in-depth analysis and debate of foreign policy, geopolitics and international affairs.', 'US News is a recognized leader in college, grad school, hospital, mutual fund, and car rankings. Track elected officials, research health conditions, ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m After observing the search results, I can see that there are many different sources and topics for current affairs in 2021.\n",
      "Action: Search\n",
      "Action Input: \"top current affairs 2021 sources\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Foreign Affairs is the leading magazine for in-depth analysis and debate of foreign policy, geopolitics and international affairs.', 'Two Indian news sites - financial news site livemint.com (58.6 million, up 41%) and timesofindia.com (210.3 million, up 40%) - and nbcnews.com ( ...', 'A Current Affairs subscription is one of the best known ways to improve your life in a hurry. Our print magazine is released six times a year, in a beautiful ...', 'Contains all the current affairs for the year 2022... Contains all the current affairs for the year 2020...', 'However, some popular choices include websites such as India Today, The Hindu, and Livemint. These websites offer a variety of articles and resources on current ...', 'US News is a recognized leader in college, grad school, hospital, mutual fund, and car rankings. Track elected officials, research health conditions, ...', 'View the latest news and breaking news today for U.S., world, weather, entertainment, politics and health at CNN.com.', 'Best source for current affairs: · The HINDU: Best to prepare socio-economic and political issues. · The Indian Express: · RSTV/LSTV debates: Very ...', 'The best bet to cover daily current affairs is the newspaper and following credible sources like Press Information Bureau (PIB) and Yojana Magazine.', 'Page 1. Reuters Institute. Digital News Report 2021. 10TH ... sources and have signalled this in the text or as ... Top countries. Thailand. 30% / 14%. Indonesia.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m After observing the search results, I can see that there are many different sources to choose from for current affairs. It would be best to select a few reliable sources to get a well-rounded understanding of current events.\n",
      "Final Answer: The top 5 current affairs for 2021 are: 1) Foreign policy and international affairs, covered by sources such as Foreign Affairs and US News. 2) Economic and financial news, covered by sources such as Livemint and India Today. 3) Political issues, covered by sources such as The Hindu and The Indian Express. 4) Daily current affairs, covered by sources such as newspapers and PIB. 5) Social and cultural issues, covered by sources such as Yojana Magazine and RSTV/LSTV debates.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The top 5 current affairs for 2021 are: 1) Foreign policy and international affairs, covered by sources such as Foreign Affairs and US News. 2) Economic and financial news, covered by sources such as Livemint and India Today. 3) Political issues, covered by sources such as The Hindu and The Indian Express. 4) Daily current affairs, covered by sources such as newspapers and PIB. 5) Social and cultural issues, covered by sources such as Yojana Magazine and RSTV/LSTV debates.'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"can you tell me 5 top current affairs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6c7e4f2b-94cd-4547-aa00-47cbac79fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e95f2b94-d88a-4e51-9d29-4ebb4de1527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"wikipedia\"],llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "31e37f3c-81e2-45d0-8222-28a259407c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dffdf2a2-c1a9-40a2-b201-cba578b9650a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I have to think about what I need to do\n",
      "Action: [wikipedia]\n",
      "Action Input: recent cricket worldcup\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Sorry, I cannot answer this question as I do not have access to the necessary tools.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sorry, I cannot answer this question as I do not have access to the necessary tools.'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"can you tell me about this recent cricket worldcup?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "57f97a0f-5bab-4672-8276-c9e170f9c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m You should think about what to do\n",
      "Action: [wikipedia]\n",
      "Action Input: India GDP\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m You should think about what to do\n",
      "Action: [google]\n",
      "Action Input: India GDP\u001b[0m\n",
      "Observation: [google] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m You should think about what to do\n",
      "Action: [wikipedia]\n",
      "Action Input: GDP of India\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m You should think about what to do\n",
      "Action: [wikipedia]\n",
      "Action Input: Economy of India\u001b[0m\n",
      "Observation: [wikipedia] is not a valid tool, try one of [wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current GDP of India is $2.6 trillion USD (2019).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current GDP of India is $2.6 trillion USD (2019).'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"can you tell me what is current GDP of India?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93c515-3166-4cec-9db5-9dc4f13e2204",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d118bf-0dba-464d-8031-ca7658e76219",
   "metadata": {},
   "source": [
    "Central to LangChain is a vital component known as LangChain Chains, forming the core connection among one or several large language models (LLMs). In certain sophisticated applications, it becomes necessary to chain LLMs together, either with each other or with other elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "243b8293-55b0-466c-8362-e7a84234545d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x00000184729FC470>, async_client=<openai.resources.completions.AsyncCompletions object at 0x00000184722068A0>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "99e30708-2752-4569-bf83-7c0977d49308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt=PromptTemplate.from_template(\"what is a good name for a company that makes {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9e6f9c8f-b652-40dc-b921-e3ef9b4f9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "62ead6a0-614e-449b-9517-8d1570b9c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "56f176b9-7edc-4c84-a82c-47dd25caa652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Vineyard Provisions\"'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Wine\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238b9c0-0317-4bec-9cc8-3ae3fd4a3f56",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7a00faa7-3ebf-43cb-b412-37bd660b0242",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"i want to open a restaurent for {cuisine} food, suggest a fency name for this\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bda35722-30d0-48da-a6ba-2f13369a1ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['cuisine'], template='i want to open a restaurent for {cuisine} food, suggest a fency name for this')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c20e6b78-0c31-4bba-ae32-b49d92be6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7479d6ce-c062-4264-ab65-42c3de7f64f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Spice Palace\"'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"indian\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "59fc7928-bf87-4c1d-b1a9-e172bfd2c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client,prompt=prompt_template,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "93f3744a-1352-4e4b-9369-71806ce7ec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mi want to open a restaurent for american food, suggest a fency name for this\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Stateside Bistro\"'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"american\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a4492-7b90-43f3-abc2-1a77f1c26f05",
   "metadata": {},
   "source": [
    "**If we want to combine multiple chain and set a seqence for that we use simplesequential chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "250ca065-216a-49aa-9118-37f4b96518fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "input_variables=[\"startup_name\"],\n",
    "    template=\"I want to start a startup for {startup-name} , suggest me a good name for this\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c63284f2-7ef9-4608-8944-b2610e00e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain=LLMChain(llm=client,prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0ad36026-0d4e-4aa6-847d-6a77b9ced58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items=PromptTemplate(\n",
    "input_variables=[\"name\"],\n",
    "    template=\"suggest some strategies for {name}\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1b4deb01-ae16-4364-8ba4-f2cd2773a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_chain=LLMChain(llm=client,prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e1833770-211d-44df-a329-7e4921be7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4c26c634-6d5b-491f-8bda-7d288029c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SimpleSequentialChain(chains=[name_chain,strategies_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "45223f4f-cf19-44f5-8945-bfb7507f0502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"MindMeld AI\" Strategies:\n",
      "- Develop a strong brand identity and establish a unique selling proposition to differentiate from other AI companies\n",
      "- Collaborate with universities and research institutions to stay on the cutting edge of AI technology\n",
      "- Offer customizable solutions for different industries and businesses\n",
      "- Utilize social media and content marketing to increase brand awareness and showcase the capabilities of MindMeld AI\n",
      "- Host webinars and workshops to educate potential clients on the benefits and applications of AI technology\n",
      "- Partner with other companies and organizations to expand reach and access to new markets\n",
      "- Continuously gather and analyze feedback from clients to improve and enhance the AI technology\n",
      "\n",
      "2. \"NeuroGenix\" Strategies:\n",
      "- Conduct market research to identify the industries and businesses that can benefit the most from NeuroGenix's technology\n",
      "- Develop a user-friendly and visually appealing interface to make the technology more accessible to non-technical users\n",
      "- Offer free trials and demos to potential clients to showcase the effectiveness and capabilities of NeuroGenix\n",
      "- Collaborate with universities and research institutions to stay updated on the latest developments in neuroscience and brain-computer interface technology\n",
      "- Attend and present at industry conferences and events to network and establish partnerships\n",
      "- Utilize targeted advertising and social media campaigns to reach potential\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"artifical intelligence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c8866-7ac3-460d-9d8e-3f11d685eb8d",
   "metadata": {},
   "source": [
    "#### Now lets try to understand the \"Sequential chain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "73acc148-d19f-460f-b9f2-6ba7f07afc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"cuisine\"],\n",
    "    template=\"i want to open a restaurant for {cuisine}, suggest a fency name for it\"\n",
    ")\n",
    "\n",
    "name_chain=LLMChain(llm=client, prompt=prompt_template_name,output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "efbffa69-1335-4009-8bd8-bf082faf9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates_items=PromptTemplate( \n",
    "    input_variables=[\"restaurant_name\"],\n",
    "    template=\"suggest some menu items for {restaurant_name}\"\n",
    "    \n",
    ")\n",
    "\n",
    "food_items_chain=LLMChain(llm=client, prompt=prompt_templates_items, output_key=\"menu_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "be36b21e-7cdb-4f27-ba34-b579e0a642e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e4d71f78-c38e-4461-bb4d-d443ab09780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SequentialChain(chains=[name_chain, food_items_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\",\"menu_items\"]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4cad3d37-70a1-4a2b-8553-d9a9b3da5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gissp\\anaconda3\\envs\\testingaopenai\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'indian',\n",
       " 'restaurant_name': '\\n\\n\"Spice Symphony\"',\n",
       " 'menu_items': '\\n\\n1. Chicken Tikka Masala: Tender pieces of chicken cooked in a creamy tomato and spice sauce.\\n2. Lamb Vindaloo: Spicy and tangy lamb curry with potatoes.\\n3. Palak Paneer: Homemade cottage cheese cubes cooked in a rich spinach and cream gravy.\\n4. Chana Masala: Chickpeas cooked in a flavorful onion and tomato gravy.\\n5. Tandoori Chicken: Marinated chicken cooked in a clay oven and served with rice and naan.\\n6. Aloo Gobi: Cauliflower and potato curry cooked with Indian spices.\\n7. Butter Chicken: Popular North Indian dish with succulent chicken pieces cooked in a rich buttery gravy.\\n8. Vegetable Biryani: Fragrant basmati rice cooked with mixed vegetables and spices.\\n9. Dal Makhani: Creamy and rich black lentil curry cooked with butter and cream.\\n10. Mango Lassi: A refreshing yogurt-based drink with sweet mango flavor.'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"cuisine\":\"indian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898959b-c8ff-4385-81f7-949b8d9254a6",
   "metadata": {},
   "source": [
    "### Document loders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bc5d08f8-d33b-4734-b853-d516756116b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (4.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fa027389-9bde-426e-a4c8-4159012e58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3044dd-48be-41c6-b72e-77f3ecd7cbbd",
   "metadata": {},
   "source": [
    "loader = PyPDFLoader(r\"C:\\Users\\gissp\\Downloads\\Generative ai.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce416dd-6495-4d53-8663-7908d25c762f",
   "metadata": {},
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb27d8c-46ab-4992-ab73-09619353aad6",
   "metadata": {},
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66aadc-0bc4-4e62-bc99-3cdea0c13b78",
   "metadata": {},
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b4f6db-3404-4a9e-97a4-8c6cfb688446",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1fd715-b4eb-4b0f-8c43-4fb3beb1c183",
   "metadata": {},
   "source": [
    "![memory](memory_lanchain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeaaa73-3e19-438e-8815-27e800eb793b",
   "metadata": {},
   "source": [
    "## Memory in LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "055e8d4f-5240-4fa8-9e2b-ed44f162ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b8b76402-5c8f-454e-8197-9fc660e66f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b54cab34-82c9-45a6-9f45-bae921b9abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_key = \"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\"\n",
    "llm = OpenAI(api_key= my_key)\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1a08c8ef-1479-4115-bd49-318415cdbffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
      "\n",
      "\n",
      "Human: Hi there my friend\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! It's nice to meet you. How are you doing today?\""
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Hi there my friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b97d1e0e-ea4f-44f2-b863-64a2cb6535cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
      "\n",
      "Human: Hi there my friend\n",
      "AI:  Hello! It's nice to meet you. How are you doing today?\n",
      "Human: Not too bad - how are you?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I am doing well, thank you for asking. Is there anything you would like to talk about?'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Not too bad - how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05a7913-1c87-401f-a3e6-038edf797a33",
   "metadata": {},
   "source": [
    "## Adding Memory to a chat model-based LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ec842c66-8626-400f-ae8e-5b1832f6a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fc372d38-3f13-4589-b47c-515ab06fa21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a chatbot having a conversation with a human.\"\n",
    "        ),  # The persistent system prompt\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  # Where the memory will be stored.\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),  # Where the human input will injected\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "18e4e7e0-e2a3-4dc7-903f-4ff84d1f2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key= my_key)\n",
    "\n",
    "chat_llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "662c86c7-b886-412d-bdea-c489748f156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human.\n",
      "Human: Hi there my friend\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How are you today?'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.predict(human_input=\"Hi there my friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5a1c0381-576c-4ec3-a74b-eda2627748e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human.\n",
      "Human: Hi there my friend\n",
      "AI: Hello! How are you today?\n",
      "Human: Not too bad - how are you?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm just a computer program, so I don't have feelings, but I'm here to chat with you. What's on your mind today?\""
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.predict(human_input=\"Not too bad - how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b19a4-60eb-45b6-9212-fcda6171cabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b0815-6d9b-4ab0-9c53-6c7a3a638748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a94e7b-cbe3-4127-8fe7-eb320b09a030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf5225-5d07-4661-a66f-3e98ed334230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "519815f2-fa03-4c07-ab84-d7ffa8d225af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(api_key=my_key,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b1f8e9b4-66f9-4b04-81be-4e4bab67df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it is by default set to \"AI\"\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2b6f8886-0839-4a91-9228-7b0a26d5fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Hello! It's nice to meet you. I am an AI created by OpenAI. I am constantly learning and improving my abilities through machine learning algorithms. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"Hi there!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "167d97c0-0dbd-496c-b957-1972c712b5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hello! It's nice to meet you. I am an AI created by OpenAI. I am constantly learning and improving my abilities through machine learning algorithms. How can I assist you today?\n",
      "Human: What's the weather?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I am not able to access real-time weather data, but based on my current location and time, I can tell you that it is currently 75 degrees Fahrenheit with partly cloudy skies. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What's the weather?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "07e401a7-2441-480b-ab53-ed5d5db5904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hello! It's nice to meet you. I am an AI created by OpenAI. I am constantly learning and improving my abilities through machine learning algorithms. How can I assist you today?\n",
      "Human: What's the weather?\n",
      "AI:  I am not able to access real-time weather data, but based on my current location and time, I can tell you that it is currently 75 degrees Fahrenheit with partly cloudy skies. Is there anything else you would like to know?\n",
      "Human: My location is Bhubaneswar,Odisha. What's the weather?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' According to my database, the current weather in Bhubaneswar, Odisha is 82 degrees Fahrenheit with mostly sunny skies. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My location is Bhubaneswar,Odisha. What's the weather?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c4e30607-27ad-46c9-abf2-13e1dbf4caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can override it and set it to \"AI Assistant\"\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI Assistant:\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory(ai_prefix=\"AI Assistant\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9d5fc4ea-2a17-40f0-8ddd-d6d76e5afce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! It's nice to meet you. My name is AI Assistant and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "15ab37e8-003c-4516-b791-76462cce9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI Assistant:  Hello! It's nice to meet you. My name is AI Assistant and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
      "Human: What's the weather?\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The weather is currently sunny with a temperature of 75 degrees Fahrenheit. There is a slight breeze coming from the east at 5 miles per hour. The humidity is at 50% and there is a 0% chance of rain. Is there anything else you would like to know about the weather?'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What's the weather?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4375ce-f00c-4bd1-ac97-57e29ee95266",
   "metadata": {},
   "source": [
    "## Human prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "852eac51-a6fe-40e8-83f8-5d0fa0b29de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can override it and set it to \"Friend\"\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Friend: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory(human_prefix=\"Friend\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a9abccf1-8a1d-406d-89c3-b79e019fea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Friend: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! It's nice to meet you. My name is AI and I am an artificial intelligence programmed to assist and communicate with humans. How can I help you today?\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6f7a6b8c-77d2-4a76-aa6c-93ba42d201fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Friend: Hi there!\n",
      "AI:  Hello! It's nice to meet you. My name is AI and I am an artificial intelligence programmed to assist and communicate with humans. How can I help you today?\n",
      "Friend: What's the weather?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The weather is currently sunny with a temperature of 75 degrees Fahrenheit. There is a slight breeze coming from the east and the humidity is at 50%. There is a 10% chance of rain later in the day. Is there anything else you would like to know about the weather?'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What's the weather?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2cfaa-c0b4-46db-b5d7-0650ae2aab20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6587f7-2808-4c83-bf33-93c3d574eb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe0db6-26a6-48e7-a2dc-2303a84319c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19ed02-1c2c-4863-9340-75c9d6d148b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fcc77242-2251-43b1-a148-39ef44c550b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langchain_openai) (0.1.39)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langchain_openai) (1.16.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (0.1.39)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.6.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain_openai) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\gissp\\anaconda3\\envs\\testingaopenai\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gissp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain_openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "03269f4e-83f0-468d-9e25-eacbd76cffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6cf89106-a1c3-4618-8840-cc4eb2b164f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi!\\nAI: what's up?\"}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2cc51d7a-373b-4fe4-9278-927b05c9f46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: hi!\\nAI: what's up?\"}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'chat_history': \"Human: hi!\\nAI: what's up?\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632557c7-4522-41e0-83c5-d376a1a10a78",
   "metadata": {},
   "source": [
    "### Using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6a800636-1b11-4b31-be3b-de8467fcc724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Provide your OpenAI API key here\n",
    "api_key = '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'\n",
    "\n",
    "llm = OpenAI(openai_api_key=api_key, temperature=0)\n",
    "# Notice that \"chat_history\" is present in the prompt template\n",
    "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human question: {question}\n",
    "Response:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# Notice that we need to align the `memory_key`\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "60959575-2279-4197-94f3-210162ac2a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a nice chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "\n",
      "\n",
      "New human question: hi\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'hi',\n",
       " 'chat_history': '',\n",
       " 'text': ' Hello! How are you doing today?'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
    "conversation({\"question\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3738de-659d-4922-89cb-987b0ab4c458",
   "metadata": {},
   "source": [
    "### Using an ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b3ea9ab1-467d-4763-ada9-45c94dadd45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "api_key = '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'\n",
    "\n",
    "llm = OpenAI(openai_api_key=api_key, temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "823326a3-6687-44a5-84ec-42ffb330461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'hi',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='\\nSystem: Hello! How are you doing today?')],\n",
       " 'text': '\\nSystem: Hello! How are you doing today?'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
    "conversation({\"question\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146cd8f-e9d2-4030-ac3a-0d738de0c628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5431ece-fb0f-4487-bb89-710430eb975c",
   "metadata": {},
   "source": [
    "### Chat Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1854a7f6-c043-435d-86bd-6801474c7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"heyy!\")\n",
    "\n",
    "history.add_ai_message(\"whats up Soman?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea00d302-e55b-40e6-82d9-86e06a2201f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='heyy!'), AIMessage(content='whats up Soman?')]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad201fe-91aa-477c-985e-62d5ad013002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175bb5d-e5b9-4eca-99c5-0cd4a4feb160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd4235-72ff-4355-98b0-e460d5ee588c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a681151-21bc-40b9-b32e-293a4cebeb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110bd792-793c-4a22-b324-eff2955d93a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb61a00-be1b-4417-9075-bf2909dbb61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5c8e8-d4b0-46e2-9299-53fde3951b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cc36e-216c-4ffd-b5b7-3481db9f91aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591914c-a013-4c60-948b-ab206b28a745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4e7cdf2-013b-451a-83ac-222f7d2b2327",
   "metadata": {},
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key= my_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a helpful assistant\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"how i can make money?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"There are many ways to make money, depending on your skills, interests, and available resources. Here are some common ways to make money:\\n\\n1. Get a job: This is the traditional way to make money, by working for an employer in exchange for a salary or wages.\\n\\n2. Start a business: If you have a business idea or a skill that you can monetize, you can start your own business to generate income.\\n\\n3. Freelancing: If you have a marketable skill, such as writing, graphic design, programming, or photography, you can offer your services on a freelance basis to clients.\\n\\n4. Investing: You can invest your money in stocks, bonds, real estate, or other assets to generate income and build wealth over time.\\n\\n5. Selling products or services online: You can sell products or services online through platforms like Etsy, eBay, or Shopify.\\n\\n6. Online surveys or market research: Some companies pay for your opinions by participating in online surveys or market research studies.\\n\\nRemember, making money takes time, effort, and sometimes a bit of trial and error. It's important to set realistic goals, be persistent, and continuously look for opportunities to increase your income.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21edd63-1413-4011-a99e-5f062bf8b04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
